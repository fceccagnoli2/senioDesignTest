{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# V1 of Predictive Modeling Approach\n",
    "Whit Blass\n",
    "September 2022"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "temp = pd.read_csv('model_data.csv')\n",
    "temp['late_bin'] = np.where(temp['days_late'] > 0, 1, 0)\n",
    "temp.to_csv('cat_model.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build Data Class to house and clean data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "#Arguments to use for data class\n",
    "features = [\n",
    "    # 'Material_Group',\n",
    "    'expected_lead_time',\n",
    "    'material_order_history',\n",
    "    'avg_material_late',\n",
    "    'supplier_material_order_history',\n",
    "    'avg_supplier_material_late',\n",
    "    'supplier_total_order_history',\n",
    "    'avg_supplier_general_late',\n",
    "    'number_line_items',\n",
    "    'avg_MOQ',\n",
    "    'avg_unit_price',\n",
    "    'avg_min_price',\n",
    "    # 'delivery_month',\n",
    "    # 'dayofweek',\n",
    "    # 'time',\n",
    "    # 'delivery_season'\n",
    "]\n",
    "target = \"late_bin\"\n",
    "categorical = [\n",
    "    'Material_Group',\n",
    "    'delivery_month',\n",
    "    'dayofweek',\n",
    "    'delivery_season'\n",
    "]\n",
    "dates = [\n",
    "    'Scheduled_relevant_delivery_date'\n",
    "]\n",
    "split_date = pd.to_datetime(\"2022-04-01\")\n",
    "split='split_by_time'\n",
    "path='cat_model.csv'\n",
    "end_date = pd.to_datetime(\"2022-05-01\")\n",
    "start_date = pd.to_datetime(\"2019-01-01\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning ingestion ========---------------------------------------------==========\n",
      "Data size:\n",
      "  Number of Rows: 67284\n",
      "  Number of Features: 11\n",
      "  Number of Targets: 1\n",
      "Cutting off date ranges:\n",
      "  Before: 2022-05-01 00:00:00\n",
      "  After: 2019-01-01 00:00:00\n",
      "Dropping rows with null values and outside date range:\n",
      "  Dropped 7119 rows\n",
      "  60165 rows left\n",
      "Dropping rows with outlier target variables:\n",
      "  Dropped 0 rows\n",
      "  60165 rows left\n",
      "Allocation complete ========---------------------------------------------==========\n",
      "\n",
      "Separating data into train and test sets ========------------------------==========\n",
      "  Length of actual training data is 58909\n",
      "  Length of actual testing data is 1256\n",
      "Train/Test split complete. ========-------------------------------------==========\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ng/clzczwr96wz__2znzb2hjykr0000gn/T/ipykernel_81807/3778207037.py:35: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  cleaner_data = clean_data[split_index]\n",
      "/var/folders/ng/clzczwr96wz__2znzb2hjykr0000gn/T/ipykernel_81807/3778207037.py:74: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  x_train, x_test = self.x_data[split_index], self.x_data[~split_index]\n"
     ]
    }
   ],
   "source": [
    "class IngestionPipe:\n",
    "    def __init__(self, features:list, target:str, categorical:list, dates:list=None, post_date=None, pre_date=None):\n",
    "        self.data = None\n",
    "        self.x_data = None\n",
    "        self.y_data = None\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "        self.x_test = None\n",
    "        self.y_test = None\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.categorical = categorical\n",
    "        self.dates = dates\n",
    "        self.post_date = post_date\n",
    "        self.pre_date = pre_date\n",
    "\n",
    "    def dataAllocation(self,path):\n",
    "        # TODO: Separate out the x_data and y_data and return each\n",
    "        # args: string path for .csv file\n",
    "        # return: None\n",
    "        # -------------------------------\n",
    "        print(\"Beginning ingestion ========---------------------------------------------==========\")\n",
    "        all_data = pd.read_csv(path)\n",
    "        if self.dates != None:\n",
    "            for date_feild in self.dates:\n",
    "                all_data[date_feild] = pd.to_datetime(all_data[date_feild], format='%Y-%m-%d')\n",
    "        f_data = all_data[self.features+[self.target]]\n",
    "        self.data = all_data\n",
    "        print(f\"Data size:\\n  Number of Rows: {len(all_data)}\\n  Number of Features: {len(self.features)}\\n  Number of Targets: 1\")\n",
    "        # Get rid of null values\n",
    "        clean_data = f_data.dropna()\n",
    "        # get rid of unwanted dates\n",
    "        print(f\"Cutting off date ranges:\\n  Before: {self.post_date}\\n  After: {self.pre_date}\")\n",
    "        split_index = (all_data['Scheduled_relevant_delivery_date'] <= self.post_date) & (all_data['Scheduled_relevant_delivery_date'] <= self.post_date)\n",
    "        cleaner_data = clean_data[split_index]\n",
    "        print(\"Dropping rows with null values and outside date range:\")\n",
    "        print(f\"  Dropped {len(f_data)-len(cleaner_data)} rows\\n  {len(cleaner_data)} rows left\")\n",
    "        print(\"Dropping rows with outlier target variables:\")\n",
    "        outlier_index = (cleaner_data[self.target] <= 10) & (cleaner_data[self.target] >= -10)\n",
    "        cleanest_data = cleaner_data[outlier_index]\n",
    "        print(f\"  Dropped {len(cleaner_data)-len(cleanest_data)} rows\\n  {len(cleanest_data)} rows left\")\n",
    "        # Separate into clean X and clean Y\n",
    "        x_data = cleanest_data[self.features]\n",
    "        y_data = cleanest_data[self.target]\n",
    "        # -------------------------------\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        print('Allocation complete ========---------------------------------------------==========\\n')\n",
    "\n",
    "    def categoricalFixing(self):\n",
    "        # TODO: create binary feature for all categorical features\n",
    "        # args: self\n",
    "        # return: None\n",
    "        # -------------------------------\n",
    "        print(\"Preparing categorical variables ========---------------------------------==========\")\n",
    "        dummy_data = pd.get_dummies(self.x_data, prefix=self.categorical, prefix_sep='-', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None)\n",
    "        print(f'  Number of categorical variables: {len(self.categorical)}')\n",
    "        print(f'  Number of new binary variables created: {len(dummy_data.columns) - len(self.features) + len(self.categorical)}')\n",
    "        self.x_data = dummy_data\n",
    "        self.features = self.x_data.columns\n",
    "        print(f'  Total number of features now: {len(self.features)}')\n",
    "        print(\"Done binarizing variables ========---------------------------------------==========\\n\")\n",
    "\n",
    "    def trainSets(self, split, split_date = None):\n",
    "        # Split data into train and test sets.\n",
    "        # args: type of split: arguments can be in {random_split, split_by_time}\n",
    "        # return: None\n",
    "        # -------------------------------\n",
    "        print(\"Separating data into train and test sets ========------------------------==========\")\n",
    "        if split == \"random_split\":\n",
    "            x_train, x_test, y_train, y_test = train_test_split(self.x_data,self.y_data, test_size=0.25, train_size=None, random_state=614, shuffle=True, stratify=None)\n",
    "        if split == \"split_by_time\":\n",
    "            split_index = data.data['Scheduled_relevant_delivery_date'] <= split_date\n",
    "            x_train, x_test = self.x_data[split_index], self.x_data[~split_index]\n",
    "            y_train, y_test = self.y_data[split_index], self.y_data[~split_index]\n",
    "        else:\n",
    "            print('  WARNING: Split type incompatible. Using random split.')\n",
    "            x_train, x_test, y_train, y_test = train_test_split(self.x_data,self.y_data, test_size=0.25, train_size=None, random_state=614, shuffle=True, stratify=None)\n",
    "        # Check that data was sampled correctly\n",
    "        print(\"  Length of actual training data is\",len(y_train))\n",
    "        print(\"  Length of actual testing data is\",len(y_test))\n",
    "        # -------------------------------\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        print('Train/Test split complete. ========-------------------------------------==========\\n')\n",
    "\n",
    "    def OverSampling(self):\n",
    "\n",
    "        os = SMOTE(random_state=0)\n",
    "        os_data_x,os_data_y=os.fit_resample(self.x_train, self.y_train)\n",
    "        os_data_x = pd.DataFrame(data=os_data_x,columns=features)\n",
    "        os_data_y = pd.DataFrame(data=os_data_y,columns=[self.target])[self.target]\n",
    "        # Check that data was oversampled correctly\n",
    "        print(\"length of actual training data is\",len(self.y_train))\n",
    "        print(\"length of training data after running SMOTE is\",len(os_data_x))\n",
    "        print(\"Number of 'late' in actual training data\",len(self.y_train[self.y_train==1]))\n",
    "        print(\"Number of 'late' in after running SMOTE is\",len(os_data_y[os_data_y==1]))\n",
    "        print(\"Proportion of 'late' data in actual training data is\",len(self.y_train[self.y_train==1])/len(self.y_train))\n",
    "        print(\"Proportion of 'late' after running SMOTE is\",len(os_data_y[os_data_y==1])/len(os_data_x))\n",
    "        # -------------------------------\n",
    "        self.x_train = os_data_x\n",
    "        self.y_train = os_data_y\n",
    "##################################################\n",
    "##### Do not add anything below this line ########\n",
    "data = IngestionPipe(features=features, target=target, categorical=categorical, dates=dates, pre_date=start_date, post_date=end_date)\n",
    "data.dataAllocation(path=path)\n",
    "# data.categoricalFixing()\n",
    "data.trainSets(split=split, split_date=split_date)\n",
    "##################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of actual training data is 58909\n",
      "length of training data after running SMOTE is 106638\n",
      "Number of 'late' in actual training data 5590\n",
      "Number of 'late' in after running SMOTE is 53319\n",
      "Proportion of 'late' data in actual training data is 0.09489212174710146\n",
      "Proportion of 'late' after running SMOTE is 0.5\n"
     ]
    }
   ],
   "source": [
    "data.OverSampling()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "        expected_lead_time  material_order_history  avg_material_late  \\\n0                     84.0                   321.0          -6.476636   \n1                     78.0                  2332.0          -6.687590   \n2                      1.0                  6109.0           0.255852   \n3                      7.0                 31199.0          -0.501606   \n4                     84.0                   321.0          -6.476636   \n...                    ...                     ...                ...   \n106633                21.0                 11390.0          -2.278994   \n106634                 7.0                 31199.0          -0.501606   \n106635                 7.0                 31199.0          -0.501606   \n106636                11.0                   321.0          -6.476636   \n106637                17.0                  1035.0           0.962626   \n\n        supplier_material_order_history  avg_supplier_material_late  \\\n0                                  27.0                    4.037037   \n1                                   7.0                   -3.285714   \n2                                5449.0                    0.272392   \n3                               30055.0                   -0.395743   \n4                                  27.0                    4.037037   \n...                                 ...                         ...   \n106633                          11388.0                   -2.279195   \n106634                          30055.0                   -0.395743   \n106635                          30055.0                   -0.395743   \n106636                             23.0                   -4.652174   \n106637                            433.0                    0.950125   \n\n        supplier_total_order_history  avg_supplier_general_late  \\\n0                               28.0                   4.035714   \n1                              349.0                  -2.155224   \n2                             5449.0                   0.272392   \n3                            30067.0                  -0.394674   \n4                               28.0                   4.035714   \n...                              ...                        ...   \n106633                       11866.0                  -2.288488   \n106634                       30067.0                  -0.394674   \n106635                       30067.0                  -0.394674   \n106636                          28.0                  -5.250000   \n106637                         433.0                   0.950125   \n\n        number_line_items       avg_MOQ  avg_unit_price  avg_min_price  \n0                      25      0.440273      517.727440      23.568771  \n1                       1      0.000268       52.358737       0.005332  \n2                       1  31012.938776       17.964587   11054.708676  \n3                      17    868.658120        3.905899     966.555355  \n4                      25      0.440273      517.727440      23.568771  \n...                   ...           ...             ...            ...  \n106633                  1   2678.519713        1.988488     347.433949  \n106634                 47    868.658120        3.905899     966.555355  \n106635                 31    868.658120        3.905899     966.555355  \n106636                  1      0.440273      517.727440      23.568771  \n106637                  1     10.853333       52.789200     303.262667  \n\n[106638 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>expected_lead_time</th>\n      <th>material_order_history</th>\n      <th>avg_material_late</th>\n      <th>supplier_material_order_history</th>\n      <th>avg_supplier_material_late</th>\n      <th>supplier_total_order_history</th>\n      <th>avg_supplier_general_late</th>\n      <th>number_line_items</th>\n      <th>avg_MOQ</th>\n      <th>avg_unit_price</th>\n      <th>avg_min_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84.0</td>\n      <td>321.0</td>\n      <td>-6.476636</td>\n      <td>27.0</td>\n      <td>4.037037</td>\n      <td>28.0</td>\n      <td>4.035714</td>\n      <td>25</td>\n      <td>0.440273</td>\n      <td>517.727440</td>\n      <td>23.568771</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>78.0</td>\n      <td>2332.0</td>\n      <td>-6.687590</td>\n      <td>7.0</td>\n      <td>-3.285714</td>\n      <td>349.0</td>\n      <td>-2.155224</td>\n      <td>1</td>\n      <td>0.000268</td>\n      <td>52.358737</td>\n      <td>0.005332</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>6109.0</td>\n      <td>0.255852</td>\n      <td>5449.0</td>\n      <td>0.272392</td>\n      <td>5449.0</td>\n      <td>0.272392</td>\n      <td>1</td>\n      <td>31012.938776</td>\n      <td>17.964587</td>\n      <td>11054.708676</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.0</td>\n      <td>31199.0</td>\n      <td>-0.501606</td>\n      <td>30055.0</td>\n      <td>-0.395743</td>\n      <td>30067.0</td>\n      <td>-0.394674</td>\n      <td>17</td>\n      <td>868.658120</td>\n      <td>3.905899</td>\n      <td>966.555355</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84.0</td>\n      <td>321.0</td>\n      <td>-6.476636</td>\n      <td>27.0</td>\n      <td>4.037037</td>\n      <td>28.0</td>\n      <td>4.035714</td>\n      <td>25</td>\n      <td>0.440273</td>\n      <td>517.727440</td>\n      <td>23.568771</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>106633</th>\n      <td>21.0</td>\n      <td>11390.0</td>\n      <td>-2.278994</td>\n      <td>11388.0</td>\n      <td>-2.279195</td>\n      <td>11866.0</td>\n      <td>-2.288488</td>\n      <td>1</td>\n      <td>2678.519713</td>\n      <td>1.988488</td>\n      <td>347.433949</td>\n    </tr>\n    <tr>\n      <th>106634</th>\n      <td>7.0</td>\n      <td>31199.0</td>\n      <td>-0.501606</td>\n      <td>30055.0</td>\n      <td>-0.395743</td>\n      <td>30067.0</td>\n      <td>-0.394674</td>\n      <td>47</td>\n      <td>868.658120</td>\n      <td>3.905899</td>\n      <td>966.555355</td>\n    </tr>\n    <tr>\n      <th>106635</th>\n      <td>7.0</td>\n      <td>31199.0</td>\n      <td>-0.501606</td>\n      <td>30055.0</td>\n      <td>-0.395743</td>\n      <td>30067.0</td>\n      <td>-0.394674</td>\n      <td>31</td>\n      <td>868.658120</td>\n      <td>3.905899</td>\n      <td>966.555355</td>\n    </tr>\n    <tr>\n      <th>106636</th>\n      <td>11.0</td>\n      <td>321.0</td>\n      <td>-6.476636</td>\n      <td>23.0</td>\n      <td>-4.652174</td>\n      <td>28.0</td>\n      <td>-5.250000</td>\n      <td>1</td>\n      <td>0.440273</td>\n      <td>517.727440</td>\n      <td>23.568771</td>\n    </tr>\n    <tr>\n      <th>106637</th>\n      <td>17.0</td>\n      <td>1035.0</td>\n      <td>0.962626</td>\n      <td>433.0</td>\n      <td>0.950125</td>\n      <td>433.0</td>\n      <td>0.950125</td>\n      <td>1</td>\n      <td>10.853333</td>\n      <td>52.789200</td>\n      <td>303.262667</td>\n    </tr>\n  </tbody>\n</table>\n<p>106638 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               late_bin   R-squared:                       0.170\n",
      "Model:                            OLS   Adj. R-squared:                  0.170\n",
      "Method:                 Least Squares   F-statistic:                     1982.\n",
      "Date:                Mon, 26 Sep 2022   Prob (F-statistic):               0.00\n",
      "Time:                        19:30:21   Log-Likelihood:                -67476.\n",
      "No. Observations:              106638   AIC:                         1.350e+05\n",
      "Df Residuals:                  106626   BIC:                         1.351e+05\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "const                               0.7052      0.003    226.413      0.000       0.699       0.711\n",
      "expected_lead_time                  0.0024   6.07e-05     39.723      0.000       0.002       0.003\n",
      "material_order_history           2.282e-06   3.18e-07      7.184      0.000    1.66e-06     2.9e-06\n",
      "avg_material_late                   0.0366      0.001     42.050      0.000       0.035       0.038\n",
      "supplier_material_order_history  1.813e-05   1.47e-06     12.305      0.000    1.52e-05     2.1e-05\n",
      "avg_supplier_material_late          0.0174      0.001     17.930      0.000       0.015       0.019\n",
      "supplier_total_order_history     -3.23e-05   1.44e-06    -22.432      0.000   -3.51e-05   -2.95e-05\n",
      "avg_supplier_general_late          -0.0076      0.001     -7.610      0.000      -0.010      -0.006\n",
      "number_line_items                  -0.0009      0.000     -6.035      0.000      -0.001      -0.001\n",
      "avg_MOQ                          -8.31e-06   1.78e-07    -46.781      0.000   -8.66e-06   -7.96e-06\n",
      "avg_unit_price                      0.0006   3.12e-05     19.486      0.000       0.001       0.001\n",
      "avg_min_price                    6.985e-08   6.01e-08      1.162      0.245    -4.8e-08    1.88e-07\n",
      "==============================================================================\n",
      "Omnibus:                    66172.448   Durbin-Watson:                   0.607\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6232.906\n",
      "Skew:                           0.126   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.843   Cond. No.                     7.40e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.4e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/whitmanblass/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "X = data.x_train\n",
    "y = data.y_train\n",
    "\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7476114649681529"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=1).fit(data.x_train, data.y_train)\n",
    "# clf.predict(data.x_test)\n",
    "clf.score(data.x_test, data.y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([1.02019407, 1.00002675, 1.00190256, 1.00013028, 1.00387097,\n        0.99981184, 1.00300453, 0.99917781, 0.99999254, 1.00455685,\n        0.99999676])]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2.72**i for i in clf.coef_]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "        expected_lead_time  material_order_history  avg_material_late  \\\n0                     84.0                   321.0          -6.476636   \n1                     78.0                  2332.0          -6.687590   \n2                      1.0                  6109.0           0.255852   \n3                      7.0                 31199.0          -0.501606   \n4                     84.0                   321.0          -6.476636   \n...                    ...                     ...                ...   \n106633                21.0                 11390.0          -2.278994   \n106634                 7.0                 31199.0          -0.501606   \n106635                 7.0                 31199.0          -0.501606   \n106636                11.0                   321.0          -6.476636   \n106637                17.0                  1035.0           0.962626   \n\n        supplier_material_order_history  avg_supplier_material_late  \\\n0                                  27.0                    4.037037   \n1                                   7.0                   -3.285714   \n2                                5449.0                    0.272392   \n3                               30055.0                   -0.395743   \n4                                  27.0                    4.037037   \n...                                 ...                         ...   \n106633                          11388.0                   -2.279195   \n106634                          30055.0                   -0.395743   \n106635                          30055.0                   -0.395743   \n106636                             23.0                   -4.652174   \n106637                            433.0                    0.950125   \n\n        supplier_total_order_history  avg_supplier_general_late  \\\n0                               28.0                   4.035714   \n1                              349.0                  -2.155224   \n2                             5449.0                   0.272392   \n3                            30067.0                  -0.394674   \n4                               28.0                   4.035714   \n...                              ...                        ...   \n106633                       11866.0                  -2.288488   \n106634                       30067.0                  -0.394674   \n106635                       30067.0                  -0.394674   \n106636                          28.0                  -5.250000   \n106637                         433.0                   0.950125   \n\n        number_line_items       avg_MOQ  avg_unit_price  avg_min_price  \n0                      25      0.440273      517.727440      23.568771  \n1                       1      0.000268       52.358737       0.005332  \n2                       1  31012.938776       17.964587   11054.708676  \n3                      17    868.658120        3.905899     966.555355  \n4                      25      0.440273      517.727440      23.568771  \n...                   ...           ...             ...            ...  \n106633                  1   2678.519713        1.988488     347.433949  \n106634                 47    868.658120        3.905899     966.555355  \n106635                 31    868.658120        3.905899     966.555355  \n106636                  1      0.440273      517.727440      23.568771  \n106637                  1     10.853333       52.789200     303.262667  \n\n[106638 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>expected_lead_time</th>\n      <th>material_order_history</th>\n      <th>avg_material_late</th>\n      <th>supplier_material_order_history</th>\n      <th>avg_supplier_material_late</th>\n      <th>supplier_total_order_history</th>\n      <th>avg_supplier_general_late</th>\n      <th>number_line_items</th>\n      <th>avg_MOQ</th>\n      <th>avg_unit_price</th>\n      <th>avg_min_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84.0</td>\n      <td>321.0</td>\n      <td>-6.476636</td>\n      <td>27.0</td>\n      <td>4.037037</td>\n      <td>28.0</td>\n      <td>4.035714</td>\n      <td>25</td>\n      <td>0.440273</td>\n      <td>517.727440</td>\n      <td>23.568771</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>78.0</td>\n      <td>2332.0</td>\n      <td>-6.687590</td>\n      <td>7.0</td>\n      <td>-3.285714</td>\n      <td>349.0</td>\n      <td>-2.155224</td>\n      <td>1</td>\n      <td>0.000268</td>\n      <td>52.358737</td>\n      <td>0.005332</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>6109.0</td>\n      <td>0.255852</td>\n      <td>5449.0</td>\n      <td>0.272392</td>\n      <td>5449.0</td>\n      <td>0.272392</td>\n      <td>1</td>\n      <td>31012.938776</td>\n      <td>17.964587</td>\n      <td>11054.708676</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.0</td>\n      <td>31199.0</td>\n      <td>-0.501606</td>\n      <td>30055.0</td>\n      <td>-0.395743</td>\n      <td>30067.0</td>\n      <td>-0.394674</td>\n      <td>17</td>\n      <td>868.658120</td>\n      <td>3.905899</td>\n      <td>966.555355</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84.0</td>\n      <td>321.0</td>\n      <td>-6.476636</td>\n      <td>27.0</td>\n      <td>4.037037</td>\n      <td>28.0</td>\n      <td>4.035714</td>\n      <td>25</td>\n      <td>0.440273</td>\n      <td>517.727440</td>\n      <td>23.568771</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>106633</th>\n      <td>21.0</td>\n      <td>11390.0</td>\n      <td>-2.278994</td>\n      <td>11388.0</td>\n      <td>-2.279195</td>\n      <td>11866.0</td>\n      <td>-2.288488</td>\n      <td>1</td>\n      <td>2678.519713</td>\n      <td>1.988488</td>\n      <td>347.433949</td>\n    </tr>\n    <tr>\n      <th>106634</th>\n      <td>7.0</td>\n      <td>31199.0</td>\n      <td>-0.501606</td>\n      <td>30055.0</td>\n      <td>-0.395743</td>\n      <td>30067.0</td>\n      <td>-0.394674</td>\n      <td>47</td>\n      <td>868.658120</td>\n      <td>3.905899</td>\n      <td>966.555355</td>\n    </tr>\n    <tr>\n      <th>106635</th>\n      <td>7.0</td>\n      <td>31199.0</td>\n      <td>-0.501606</td>\n      <td>30055.0</td>\n      <td>-0.395743</td>\n      <td>30067.0</td>\n      <td>-0.394674</td>\n      <td>31</td>\n      <td>868.658120</td>\n      <td>3.905899</td>\n      <td>966.555355</td>\n    </tr>\n    <tr>\n      <th>106636</th>\n      <td>11.0</td>\n      <td>321.0</td>\n      <td>-6.476636</td>\n      <td>23.0</td>\n      <td>-4.652174</td>\n      <td>28.0</td>\n      <td>-5.250000</td>\n      <td>1</td>\n      <td>0.440273</td>\n      <td>517.727440</td>\n      <td>23.568771</td>\n    </tr>\n    <tr>\n      <th>106637</th>\n      <td>17.0</td>\n      <td>1035.0</td>\n      <td>0.962626</td>\n      <td>433.0</td>\n      <td>0.950125</td>\n      <td>433.0</td>\n      <td>0.950125</td>\n      <td>1</td>\n      <td>10.853333</td>\n      <td>52.789200</td>\n      <td>303.262667</td>\n    </tr>\n  </tbody>\n</table>\n<p>106638 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build NN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def Vanilla_NN_Reg(self,x_train,x_test, y_train):\n",
    "        regr = MLPRegressor(hidden_layer_sizes=(12,12,12,12,12,12,12), random_state=1, solver='adam', activation='relu', alpha=.001, max_iter=500)\n",
    "        regr.fit(x_train, y_train)\n",
    "        y_predict_train = regr.predict(x_train)\n",
    "        y_predict_test = regr.predict(x_test)\n",
    "        return regr, y_predict_train, y_predict_test\n",
    "\n",
    "    def Score(self, regr, x, y):\n",
    "        # -------------------------------\n",
    "        Score = regr.score(x, y)\n",
    "        # -------------------------------\n",
    "        return Score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "class Regression():\n",
    "\n",
    "    def linearRegression(self,x_train,x_test, y_train):\n",
    "        # -------------------------------\n",
    "        regressor = LinearRegression(fit_intercept=True, positive=False)\n",
    "        regressor.fit(x_train, y_train)\n",
    "        y_predict_train = regressor.predict(x_train)\n",
    "        y_predict_test = regressor.predict(x_test)\n",
    "        # -------------------------------\n",
    "        return regressor, y_predict_train, y_predict_test\n",
    "\n",
    "    def trainMSE(self,y_train,y_predict_train):\n",
    "        # -------------------------------\n",
    "        train_mse = mean_squared_error(y_train, y_predict_train)\n",
    "        # -------------------------------\n",
    "        return train_mse\n",
    "\n",
    "    def testMSE(self,y_test,y_predict_test):\n",
    "        # -------------------------------\n",
    "        test_mse = mean_squared_error(y_test, y_predict_test)\n",
    "        # -------------------------------\n",
    "        return test_mse\n",
    "\n",
    "    def trainScore(self, regressor, x_train, y_train):\n",
    "        # -------------------------------\n",
    "        train_Score = regressor.score(x_train, y_train)\n",
    "        # -------------------------------\n",
    "        return train_Score\n",
    "\n",
    "#Feature Importance\n",
    "\n",
    "    def regGetCoef(self,regressor):\n",
    "        # -------------------------------\n",
    "        params = regressor.coef_\n",
    "        # -------------------------------\n",
    "        return params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = Regression()\n",
    "model, y_pred_train, y_pred_test = regr.linearRegression(x_train=data.x_train, x_test=data.x_test, y_train=data.y_train)\n",
    "regr.trainScore(model, data.x_train, y_pred_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "0.22824264441154407"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression(fit_intercept=True, positive=False).fit(data.x_train, data.y_train).score(data.x_train, data.y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "[(-2.3390973675611777, 4.0),\n (-2.9309020965542727, -2.0),\n (-0.06972839755004889, 0.0),\n (-0.5773668744923319, -1.0),\n (-2.3390973675611777, 4.0),\n (-0.11676383934912593, 0.0),\n (-0.5773668744923319, -1.0),\n (-2.3390973675611777, 4.0),\n (-0.5773668744923319, -1.0),\n (-2.4767137339624954, 6.0),\n (-0.5773668744923319, -1.0),\n (-2.3774339944352754, 4.0),\n (-2.3390973675611777, 4.0),\n (-1.7614064580907687, -2.0),\n (-2.3390973675611777, 4.0),\n (-0.06972839755004889, 0.0),\n (-2.3390973675611777, 4.0),\n (-0.11676383934912593, 0.0),\n (-0.5773668744923319, -1.0),\n (-2.3390973675611777, 4.0),\n (-1.8177440293266842, 0.0),\n (-2.3390973675611777, 4.0),\n (-1.8177440293266842, 0.0),\n (-2.3390973675611777, 4.0),\n (-0.5773668744923319, -1.0),\n (-0.5773668744923319, -1.0),\n (-2.3390973675611777, 4.0),\n (-0.5773668744923319, -1.0),\n (-2.565769221801963, -2.0),\n (0.006453651987873066, -2.0),\n (0.2902289329632284, 3.0),\n (-0.5773668744923319, -1.0),\n (-2.442286430331939, 4.0),\n (-2.4767137339624954, 6.0),\n (-2.3390973675611777, 4.0),\n (-0.4914915053147104, -1.0),\n (-2.202304159362374, 0.0),\n (-2.3390973675611777, 4.0),\n (-1.917678839228124, 3.0),\n (-1.8177440293266842, 0.0),\n (-2.3390973675611777, 4.0),\n (-2.3390973675611777, 4.0),\n (-0.5773668744923319, -1.0),\n (-2.3390973675611777, 4.0),\n (-0.5773668744923319, -1.0),\n (-2.3390973675611777, 4.0),\n (-1.8177440293266842, 0.0),\n (-0.11836119880221307, 0.0),\n (-2.3390973675611777, 4.0),\n (-0.9023075377587817, 3.0),\n (-0.06972839755004889, 0.0),\n (-0.5773668744923319, -1.0),\n (-0.5773668744923319, -1.0),\n (-0.11836119880221307, 0.0),\n (-1.007588006309603, -1.0),\n (-1.957054544682976, 4.0),\n (-0.06972839755004889, 0.0),\n (-1.8177440293266842, 0.0),\n (-2.3390973675611777, 4.0),\n (-1.455314967512302, 4.0),\n (-0.4914915053147104, -1.0),\n (-2.3390973675611777, 4.0),\n (-1.8177440293266842, 0.0),\n (-2.3390973675611777, 4.0),\n (-1.8177440293266842, 0.0),\n (-2.3390973675611777, 4.0),\n (-0.5773668744923319, -1.0),\n (0.3193317022612061, 3.0),\n (-2.381937077320731, 4.0),\n (-0.5773668744923319, -1.0),\n (0.249250547625389, 3.0),\n (-0.5773668744923319, -1.0),\n (-2.7408160088149414, -4.0),\n (-2.3390973675611777, 4.0),\n (-1.007588006309603, -1.0),\n (-0.5773668744923319, -1.0),\n (-0.07423148043550398, 0.0),\n (-1.8177440293266842, 0.0),\n (-0.06972839755004889, 0.0),\n (-2.3390973675611777, 4.0),\n (-1.8177440293266842, 0.0),\n (-2.3390973675611777, 4.0),\n (-0.9338291179569699, 3.0),\n (-0.7791738029932758, 0.0),\n (-1.6281792879594001, -3.0),\n (-1.6281792879594001, -3.0),\n (-1.9733076331683732, 0.0),\n (-1.0555402776508074, -5.0),\n (-1.6281792879594001, -3.0),\n (-1.4722282094737449, 0.0),\n (-1.4677251265882894, 0.0),\n (-1.481234375244656, 0.0),\n (-1.6281792879594001, -3.0),\n (-2.890341484189363, -3.0),\n (-1.6281792879594001, -3.0),\n (-1.694842776125511, -3.0),\n (-1.679736168016058, -3.0),\n (-1.6281792879594001, -3.0),\n (-1.6281792879594001, -3.0),\n (-1.6281792879594001, -3.0),\n (-2.890341484189363, -3.0),\n (-3.6142539027842773, 0.0),\n (-0.7791738029932758, 0.0),\n (-1.6281792879594001, -3.0),\n (-3.986692617284796, -5.0),\n (-1.6281792879594001, -3.0),\n (-2.890341484189363, -3.0),\n (-3.4963817851983023, -7.0),\n (-1.6281792879594001, -3.0),\n (-2.890341484189363, -3.0),\n (-1.6281792879594001, -3.0),\n (-2.890341484189363, -3.0),\n (-1.6281792879594001, -3.0),\n (-1.6281792879594001, -3.0),\n (-1.6281792879594001, -3.0),\n (-0.7947310504714697, 0.0),\n (-1.5534854349533909, -4.0),\n (-1.6281792879594001, -3.0),\n (-1.6281792879594001, -3.0),\n (-4.01541144062023, -7.0),\n (-1.679736168016058, -3.0),\n (-1.6281792879594001, -3.0),\n (-1.6281792879594001, -3.0),\n (-3.0730854689471223, 0.0),\n (-2.890341484189363, -3.0),\n (-1.6281792879594001, -3.0),\n (-2.890341484189363, -3.0),\n (-1.6649185553804111, -3.0),\n (-1.6281792879594001, -3.0),\n (-1.694842776125511, -3.0),\n (-1.6281792879594001, -3.0),\n (-2.890341484189363, -3.0),\n (-1.5534854349533909, -4.0),\n (-1.6281792879594001, -3.0),\n (-2.890341484189363, -3.0),\n (-1.6281792879594001, -3.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-2.1123491170632036, -1.0),\n (-0.834213326302367, -1.0),\n (-2.1123491170632036, -1.0),\n (-0.834213326302367, -1.0),\n (-0.35692467896874436, 0.0),\n (-2.1123491170632036, -1.0),\n (-0.834213326302367, -1.0),\n (-0.35692467896874436, 0.0),\n (-0.834213326302367, -1.0),\n (-0.4145636459918196, 0.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-0.8901209071604261, -1.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-1.296381647181386, -1.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (0.003032651544532694, 0.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-2.496909247098893, -1.0),\n (-2.1123491170632036, -1.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-0.35692467896874436, 0.0),\n (-0.35692467896874436, 0.0),\n (-0.35692467896874436, 0.0),\n (-0.834213326302367, -1.0),\n (0.03213542084251042, -1.0),\n (-0.28074262943082284, -6.0),\n (-0.834213326302367, -1.0),\n (-0.6974305612537601, -1.0),\n (-0.834213326302367, -1.0),\n (-0.35692467896874436, 0.0),\n (-0.834213326302367, -1.0),\n (-2.1123491170632036, -1.0),\n (-0.834213326302367, -1.0),\n (-2.1123491170632036, -1.0),\n (-0.37043392762511096, 0.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-0.35692467896874436, 0.0),\n (-0.834213326302367, -1.0),\n (-2.1123491170632036, -1.0),\n (-1.6861196785175663, -1.0),\n (-0.834213326302367, -1.0),\n (-0.35692467896874436, 0.0),\n (-0.35692467896874436, 0.0),\n (-0.834213326302367, -1.0),\n (-0.35692467896874436, 0.0),\n (-0.834213326302367, -1.0),\n (-2.1123491170632036, -1.0),\n (0.003032651544532694, 0.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-0.35692467896874436, 0.0),\n (-0.35692467896874436, 0.0),\n (-0.834213326302367, -1.0),\n (-0.834213326302367, -1.0),\n (-2.1123491170632036, -1.0),\n (-2.1123491170632036, -1.0),\n (-0.834213326302367, -1.0),\n (-7.628305460841191, -8.0),\n (-0.834213326302367, -1.0),\n (-2.633158507010018, -7.0),\n (-2.796684108926877, -2.0),\n (-0.5909925997436385, 1.0),\n (-0.7553718530525919, -1.0),\n (0.050479896174993044, 0.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-2.925858894564623, -7.0),\n (-0.27300213188589995, 0.0),\n (0.09145828151283242, 0.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.27300213188589995, 0.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.27300213188589995, 0.0),\n (-1.2079560172130863, -1.0),\n (-0.29551754631317717, 0.0),\n (0.12056105081081014, 0.0),\n (-0.1923169994625229, 0.0),\n (-0.7553718530525919, -1.0),\n (-2.4403179054995654, 0.0),\n (-0.7553718530525919, -1.0),\n (-2.796684108926877, -2.0),\n (-1.105581272094633, -2.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.6090049312854604, 2.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.29551754631317717, -6.0),\n (0.08506672764980383, 0.0),\n (-0.8107014429630375, -1.0),\n (-0.7553718530525919, -1.0),\n (-3.2639752559842523, -2.0),\n (-0.27300213188589995, 0.0),\n (-0.27300213188589995, 0.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.29551754631317717, 0.0),\n (-0.7553718530525919, -1.0),\n (-3.1566912453174014, -7.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.7553718530525919, -1.0),\n (-0.8332168573903143, -1.0),\n (-0.7553718530525919, -1.0),\n (-5.081585454613813, -8.0),\n (-2.719509044397804, 0.0),\n (-2.0046742492885192, -1.0),\n (-0.743531421564031, -1.0),\n (-2.0046742492885192, -1.0),\n (-0.26145069587114556, 0.0),\n (-0.26145069587114556, 0.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-2.9016588339875224, -8.0),\n (-2.0046742492885192, -1.0),\n (-0.26145069587114556, 0.0),\n (-2.0046742492885192, -1.0),\n (-0.743531421564031, -1.0),\n (-2.046357977152845, -6.0),\n (-0.8020557303806506, -1.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-0.31008349712330974, 0.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-2.0046742492885192, -1.0),\n (-0.743531421564031, -1.0),\n (0.09850663464213127, 0.0),\n (-2.3892343793242086, -1.0),\n (-0.743531421564031, -1.0),\n (-2.0046742492885192, -1.0),\n (-0.8020557303806506, -1.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-0.8978803841515044, -1.0),\n (-0.18526864633322426, -8.0),\n (-3.0574849816673693, -2.0),\n (-0.26145069587114556, 0.0),\n (-0.743531421564031, -1.0),\n (-0.26145069587114556, 0.0),\n (-0.743531421564031, -1.0),\n (-2.0046742492885192, -1.0),\n (-0.6832138036358077, 0.0),\n (-0.743531421564031, -1.0),\n (-1.5890483359668803, -2.0),\n (-2.0046742492885192, -1.0),\n (-0.743531421564031, -1.0),\n (-4.976039546211608, -6.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-1.2009076640837875, -1.0),\n (-2.0046742492885192, -1.0),\n (-0.743531421564031, -1.0),\n (-0.5884473294997952, -1.0),\n (-2.4316721929171794, 0.0),\n (-0.7946469240628276, -1.0),\n (-1.5620298386541476, 1.0),\n (-0.743531421564031, -1.0),\n (-2.0046742492885192, -1.0),\n (-0.743531421564031, -1.0),\n (0.127609403940109, 0.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-2.0046742492885192, -1.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-2.0046742492885192, -1.0),\n (-0.5929504123852507, -1.0),\n (-0.6832138036358077, 0.0),\n (-1.5890483359668803, -2.0),\n (-0.743531421564031, -1.0),\n (-0.743531421564031, -1.0),\n (-2.4316721929171794, 0.0),\n (-0.26145069587114556, 0.0),\n (-0.26145069587114556, 0.0),\n (-0.743531421564031, -1.0),\n (-1.5620298386541476, 1.0),\n (-0.743531421564031, -1.0),\n (-0.5591109352709909, -1.0),\n (-0.5591109352709909, -1.0),\n (-1.5089291290709839, -4.0),\n (-0.06265397450032006, 0.0),\n (-0.6048563684629129, -1.0),\n (-0.5591109352709909, -1.0),\n (-1.8122669657300428, -1.0),\n (0.013528075037601894, 0.0),\n (-0.5591109352709909, -1.0),\n (-1.8122669657300428, -1.0),\n (-0.5591109352709909, -1.0),\n (-0.5591109352709909, -1.0),\n (-0.5591109352709909, -1.0),\n (-0.5591109352709909, -1.0),\n (0.2563249706751174, 0.0),\n (-1.847561255782019, -4.0),\n (-1.8790828359802072, -10.0),\n (-0.394153691014425, 4.0),\n (-1.526798149138652, 5.0),\n (-0.09417555469850836, -1.0),\n (-0.5591109352709909, -1.0),\n (1.3462458584652164, -2.0),\n (-1.8122669657300428, -1.0),\n (-0.06715705738577515, 0.0),\n (-0.5591109352709909, -1.0),\n (-0.06715705738577515, 0.0),\n (-0.06265397450032006, 0.0),\n (-0.5591109352709909, -1.0),\n (-0.6257744234371017, -1.0),\n (-0.5591109352709909, -1.0),\n (-1.8122669657300428, -1.0),\n (-0.5591109352709909, -1.0),\n (-2.196827095765732, -1.0),\n (-0.06715705738577515, 0.0),\n (-0.5591109352709909, -1.0),\n (-0.06715705738577515, 0.0),\n (-1.1827474058745941, -3.0),\n (-1.727313537728307, -1.0),\n (-1.0005135832598742, -1.0),\n (-0.5591109352709909, -1.0),\n (-1.8122669657300428, -1.0),\n (-0.5591109352709909, -1.0),\n (-0.4844170822649816, -1.0),\n (-1.8122669657300428, -1.0),\n (-0.5591109352709909, -1.0),\n (-0.5591109352709909, -1.0),\n (-1.5089291290709839, -4.0),\n (-0.5591109352709909, -1.0),\n (-0.5591109352709909, -1.0),\n (-0.5778378711501797, -1.0),\n (1.359755107121583, -2.0),\n (0.2864087192644731, 0.0),\n (-0.4844170822649816, -1.0),\n (-0.5591109352709909, -1.0),\n (-1.0005135832598742, -1.0),\n (-0.5591109352709909, -1.0),\n (-0.5591109352709909, -1.0),\n (-1.8122669657300428, -1.0),\n (-0.5591109352709909, -1.0),\n (-1.8122669657300428, -1.0),\n (-1.605131270378798, -3.0),\n (-2.2051470740848194, -3.0),\n (-1.605131270378798, -3.0),\n (-0.7355878043277457, 0.0),\n (-1.605131270378798, -3.0),\n (-0.7355878043277457, -6.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-2.473163599208925, 3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-2.878474982780372, -3.0),\n (-1.465153786424016, -3.0),\n (-2.878474982780372, -3.0),\n (-2.878474982780372, -3.0),\n (-1.605131270378798, -3.0),\n (-1.1336540699099116, 0.0),\n (-2.073111038122553, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.0169442744028903, -3.0),\n (-1.605131270378798, -3.0),\n (-2.473163599208925, 3.0),\n (-1.4590533440854734, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.0484658546010786, 0.0),\n (-1.605131270378798, -3.0),\n (-2.878474982780372, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.546411011903662, -4.0),\n (-2.878474982780372, -3.0),\n (-1.6758564638725044, -3.0),\n (-2.878474982780372, -3.0),\n (-2.990610677358898, 0.0),\n (-1.605131270378798, -3.0),\n (-0.7736967393966343, 0.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-3.276813549380445, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.4590533440854734, -3.0),\n (-1.605131270378798, -3.0),\n (-1.9826481822073787, 0.0),\n (-1.605131270378798, -3.0),\n (-1.1822868711620758, 0.0),\n (-3.2630351128160613, -3.0),\n (-2.878474982780372, -3.0),\n (-3.800880705339021, -5.0),\n (-2.229923722877628, -6.0),\n (-1.605131270378798, -3.0),\n (-1.546411011903662, -4.0),\n (-2.878474982780372, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.605131270378798, -3.0),\n (-1.1336540699099116, 0.0),\n (-2.878474982780372, -3.0),\n (-1.1336540699099116, 0.0),\n (-1.605131270378798, -3.0),\n (-1.9826481822073787, 0.0),\n (-2.878474982780372, -3.0),\n (-2.878474982780372, -3.0),\n (-1.6488379665597712, -3.0),\n (-0.8303336221588136, -1.0),\n (-2.1347575372007146, -6.0),\n (-0.8303336221588136, -1.0),\n (-0.34985025591901553, 0.0),\n (-0.24214662618290572, -4.0),\n (-2.1004826156542125, -1.0),\n (-0.8303336221588136, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.8303336221588136, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.7716133636836775, 1.0),\n (-0.8303336221588136, -1.0),\n (-2.485042745689902, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.4119923058275463, 2.0),\n (-0.8303336221588136, -1.0),\n (-0.8303336221588136, -1.0),\n (0.010107074594261523, 0.0),\n (-0.8303336221588136, -1.0),\n (-0.8303336221588136, -1.0),\n (-2.1527698687425367, -8.0),\n (-0.6903561382040315, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.8303336221588136, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.8303336221588136, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.8303336221588136, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.030871310743578073, 0.0),\n (-0.8303336221588136, -1.0),\n (0.003715520731232713, 0.0),\n (-0.8303336221588136, -1.0),\n (-0.34985025591901553, 0.0),\n (-0.8303336221588136, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.8303336221588136, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.34985025591901553, 0.0),\n (-0.8303336221588136, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.48663869154985684, 0.0),\n (-0.8303336221588136, -1.0),\n (-1.7060637527805702, 2.0),\n (-0.8303336221588136, -1.0),\n (-0.8994614561994316, 0.0),\n (-1.701560669895115, 0.0),\n (-0.8303336221588136, -1.0),\n (-1.7060637527805702, 1.0),\n (-0.7716133636836775, 1.0),\n (-0.34985025591901553, 0.0),\n (-0.8303336221588136, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.8303336221588136, -1.0),\n (-2.1004826156542125, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.8303336221588136, -1.0),\n (-0.48663869154985684, 0.0),\n (-0.8303336221588136, -1.0),\n (-0.8994614561994316, -1.0),\n (-2.1004826156542125, -1.0),\n (-2.864965993933777, 0.0),\n (-0.2614246259507156, 0.0),\n (-0.28844312326344834, 0.0),\n (-0.7291291165658147, -1.0),\n (-0.2650456984549763, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.2614246259507156, 0.0),\n (-0.7291291165658147, -1.0),\n (-0.6019305082357316, 0.0),\n (-2.046331907232415, -6.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.6831877337153776, 0.0),\n (-1.2008815941633575, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-2.017427054992788, -1.0),\n (-0.2659277088361711, 0.0),\n (-0.7291291165658147, -1.0),\n (-0.8515635722002306, 0.0),\n (-0.2614246259507156, 0.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.2614246259507156, 0.0),\n (-0.7291291165658147, -1.0),\n (-0.2614246259507156, 0.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (0.09853270456256125, 0.0),\n (-0.7291291165658147, -1.0),\n (-2.017427054992788, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.8020296604602206, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.2614246259507156, 0.0),\n (-2.017427054992788, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.8020296604602206, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.5884212595793652, 0.0),\n (0.12313239097508344, 0.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-1.926084189178703, -1.0),\n (-0.2614246259507156, 0.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.7291291165658147, -1.0),\n (-2.4019871850284775, -1.0),\n (-2.864222274461276, -6.0),\n (-0.6831877337153776, 0.0),\n (-0.7291291165658147, -1.0),\n (-0.2614246259507156, 0.0),\n (-2.017427054992788, -1.0),\n (-0.7291291165658147, -1.0),\n (-0.8515635722002306, -1.0),\n (-2.3084567191880065, -3.0),\n (-0.25437627282141717, 0.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (-0.25437627282141717, 0.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (-1.6150928525684272, -8.0),\n (-1.5880743552556944, 4.0),\n (-2.00398926405114, -1.0),\n (-0.7444437957797387, -1.0),\n (-2.00398926405114, -1.0),\n (-1.6103007742091653, 0.0),\n (-1.6042003318706222, 0.0),\n (-0.6761393805860789, 0.0),\n (-0.7444437957797387, -1.0),\n (-3.869171605245985, -7.0),\n (-0.7444437957797387, -1.0),\n (-0.25437627282141717, 0.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (0.13468382698983739, -1.0),\n (-0.7444437957797387, -1.0),\n (-1.1938332410340586, -1.0),\n (-2.3885493940868296, -1.0),\n (-0.7444437957797387, -1.0),\n (-1.6042003318706222, 0.0),\n (-1.6103007742091653, 0.0),\n (-1.6042003318706222, 0.0),\n (-2.00398926405114, -1.0),\n (0.10558105769185966, 0.0),\n (-0.7444437957797387, -1.0),\n (-0.8190940812112868, -1.0),\n (-0.7444437957797387, -1.0),\n (-0.6761393805860789, 0.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (-0.3435559201493317, -2.0),\n (-0.25437627282141717, 0.0),\n (-0.7444437957797387, -1.0),\n (-0.8908059611017756, -1.0),\n (-0.17819422328349543, -8.0),\n (-3.9571399875262934, -6.0),\n (-0.7444437957797387, -1.0),\n (-1.6103007742091653, 0.0),\n (-0.25437627282141717, 0.0),\n (0.753749183338583, -8.0),\n (-2.00398926405114, -1.0),\n (-0.5858759893355219, -1.0),\n (-0.25887935570687226, 0.0),\n (-2.00398926405114, -1.0),\n (-1.6042003318706222, 0.0),\n (-3.25435556269068, -7.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (-2.61903573083099, -10.0),\n (-2.039283554103116, -6.0),\n (-0.7444437957797387, -1.0),\n (-0.7444437957797387, -1.0),\n (-2.8945844109377936, -8.0),\n (-2.00398926405114, -1.0),\n (-0.7444437957797387, -1.0),\n (-2.00398926405114, -1.0),\n (-0.7444437957797387, -1.0),\n (-1.6042003318706222, 0.0),\n (-1.6103007742091653, 0.0),\n (-0.25437627282141717, 0.0),\n (-2.00398926405114, -1.0),\n (-3.7787851247626785, -4.0),\n (-0.9950365196632328, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.8955674979771477, -1.0),\n (-1.8004004643210516, -1.0),\n (-0.5440497149558259, -1.0),\n (-1.8004004643210516, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (0.05372143773860616, -3.0),\n (-1.8004004643210516, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-1.8004004643210516, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.4548373161210737, 3.0),\n (-0.5440497149558259, -1.0),\n (-1.8004004643210516, -1.0),\n (-0.5440497149558259, -1.0),\n (-1.8004004643210516, -1.0),\n (-0.38707926796469616, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-1.4027868825412348, 3.0),\n (-0.5440497149558259, -1.0),\n (-1.8004004643210516, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.08710113164877953, 0.0),\n (-1.8004004643210516, -1.0),\n (-0.5440497149558259, -1.0),\n (-1.8004004643210516, -1.0),\n (-0.060082634336046326, -1.0),\n (-1.2071945630230536, 5.0),\n (0.30437777906268604, 3.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-2.523274007850491, -1.0),\n (-1.8179714183050129, 0.0),\n (0.33348054836066376, 3.0),\n (0.05372143773860616, -3.0),\n (-0.8955674979771477, -3.0),\n (-1.8004004643210516, -1.0),\n (-0.5440497149558259, -1.0),\n (-1.8004004643210516, -1.0),\n (-0.5440497149558259, -1.0),\n (-1.8004004643210516, -1.0),\n (-2.561249196949746, 3.0),\n (-0.5440497149558259, -1.0),\n (-1.7202391146785783, -1.0),\n (-0.5440497149558259, -1.0),\n (-0.5440497149558259, -1.0),\n (-1.8648449715243567, -1.0),\n (-2.8682058408244684, -3.0),\n (-2.9024807623709705, -6.0),\n (-1.5996542067821564, -3.0),\n (-2.066036615072824, 0.0),\n (-1.5996542067821564, -3.0),\n (-1.97557375915765, -4.0),\n (-1.0082724919000743, -6.0),\n (-2.8682058408244684, -3.0),\n (-1.1265796468601827, 0.0),\n (-2.8682058408244684, -3.0),\n (-2.1935695681496354, 2.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.1265796468601827, 0.0),\n (-1.5393365888539337, -4.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.175212448112347, -3.0),\n (-2.8682058408244684, -3.0),\n (-1.1265796468601827, 0.0),\n (-1.5996542067821564, -3.0),\n (-1.1265796468601827, 0.0),\n (-1.5996542067821564, -3.0),\n (-1.6639899624635133, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.97557375915765, -4.0),\n (-2.8682058408244684, -3.0),\n (-1.1265796468601827, 0.0),\n (-2.8682058408244684, -3.0),\n (-1.1265796468601827, 0.0),\n (-7.637631144554429, -10.0),\n (-1.1347038022498985, 1.0),\n (-2.8682058408244684, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.4580793633742872, 0.0),\n (-1.0082724919000743, -6.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.4535762804888321, 0.0),\n (-0.7285133812780169, 0.0),\n (-1.5996542067821564, -3.0),\n (-2.5053085581490144, 2.0),\n (-1.5996542067821564, -3.0),\n (-1.6639899624635133, -3.0),\n (-1.1265796468601827, 0.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-3.252765970860158, -3.0),\n (-1.1265796468601827, 0.0),\n (-2.8682058408244684, -3.0),\n (-1.1265796468601827, 0.0),\n (-1.5996542067821564, -3.0),\n (-1.1265796468601827, 0.0),\n (-3.1401323472576728, 0.0),\n (-2.8682058408244684, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.1347038022498985, 1.0),\n (-1.5996542067821564, -3.0),\n (-1.6639899624635133, -3.0),\n (-1.1265796468601827, 0.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, 0.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-2.8682058408244684, -3.0),\n (-2.8682058408244684, -3.0),\n (-1.1265796468601827, 0.0),\n (-2.8682058408244684, -3.0),\n (-1.1347038022498985, 1.0),\n (-1.1265796468601827, 0.0),\n (-1.5393365888539337, -4.0),\n (-1.1265796468601827, 0.0),\n (-1.6806939300260533, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.1265796468601827, 0.0),\n (-1.5996542067821564, -3.0),\n (-1.1265796468601827, 0.0),\n (-5.1829170570848575, -6.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-1.6639899624635133, -3.0),\n (-1.1265796468601827, 0.0),\n (-1.5996542067821564, -3.0),\n (-1.5996542067821564, -3.0),\n (-7.637631144554429, -10.0),\n (-2.8682058408244684, -3.0),\n (-2.1276831141509858, 0.0),\n (-2.0997976304168335, -1.0),\n (0.04628426694196763, 0.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8923870331497028, -1.0),\n (-3.0775487115802287, -5.0),\n (-0.8104803234843858, -1.0),\n (-1.2822328010819284, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.7645389406339487, 1.0),\n (-0.8104803234843858, -1.0),\n (-12.218684637283758, 3.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-2.0997976304168335, -1.0),\n (-2.145695445692808, -8.0),\n (-2.3021513061695016, 0.0),\n (-2.0997976304168335, -1.0),\n (-0.8104803234843858, -1.0),\n (-1.6764739153035642, 1.0),\n (-0.8104803234843858, -1.0),\n (-4.843878062665933, -4.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.7645389406339487, 1.0),\n (-0.9074936412591565, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.23347484368008953, -6.0),\n (-2.9823418639359915, -5.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-2.0997976304168335, -1.0),\n (-2.0997976304168335, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-1.2023734703907525, -7.0),\n (-0.8104803234843858, -1.0),\n (-0.6771812728157598, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.0057845561520275535, 0.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-1.727316191022855, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-2.0997976304168335, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-2.0997976304168335, -1.0),\n (-2.0997976304168335, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8923870331497028, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (-2.0997976304168335, -1.0),\n (-0.6832817151543027, -1.0),\n (-2.0997976304168335, -1.0),\n (-0.8104803234843858, -1.0),\n (-0.8104803234843858, -1.0),\n (0.01718149764399035, 0.0),\n (-0.7172626151568238, -1.0),\n (-2.008755272489972, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.3083871975264527, 0.0),\n (-1.1922098116605415, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.2543502029009872, 0.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (0.13020681402481227, 0.0),\n (-0.2543502029009872, 0.0),\n (-0.7172626151568238, -1.0),\n (-0.2579712754052479, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.676113310665649, 0.0),\n (-0.5957024918144076, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-1.1922098116605415, -1.0),\n (0.09921557374926149, 1.0),\n (-0.7172626151568238, -1.0),\n (-0.794955237410492, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-2.008755272489972, -1.0),\n (0.10560712761229007, 0.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.676113310665649, 0.0),\n (-2.457690639598296, 0.0),\n (-0.14664657316487717, -6.0),\n (-2.613398987026511, 0.0),\n (-0.7172626151568238, -1.0),\n (0.1347098969102678, 0.0),\n (-0.17816815336306546, -6.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-4.973442136126905, -8.0),\n (-0.2543502029009872, 0.0),\n (-0.7172626151568238, -1.0),\n (-2.3933154025256616, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.794955237410492, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.5813468365296364, 0.0),\n (-0.5948560851860027, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.2543502029009872, 0.0),\n (-1.3438555386177171, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.2543502029009872, 0.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-2.008755272489972, -1.0),\n (-0.7172626151568238, -1.0),\n (-2.008755272489972, 0.0),\n (-0.7650310166653911, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.3029830041531514, 0.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-0.7172626151568238, -1.0),\n (-2.008755272489972, -1.0),\n (-0.7182010592929615, -1.0),\n (-0.7182010592929615, -1.0),\n (-0.7182010592929615, -1.0),\n (-0.7182010592929615, -1.0),\n (-0.7182010592929615, -1.0),\n (-1.9937201220952363, -1.0),\n (-0.7182010592929615, -1.0),\n (-0.7182010592929615, -1.0),\n (-0.25092292227594903, -2.0),\n (-0.7182010592929615, -1.0),\n ...]"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(y_pred_train, data.y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x7fef5945a9a0>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlQ0lEQVR4nO3df5DcdZ3n8ee7m+9QPXMuk5EJwpCIl83FFbMJayoJm7pduFXDUq4MSIAs7LI/iuiW3p2nm3IRa0U3FK5zsFqyLocede6JEREYs7doxC2q3HUlMJCEiBL5sTHJhCLDhqCS0Uwm7/ujuyc93d9v/5j+frun+/t6VE1N97e/3f3pb3fmnf5+P6/v29wdERFJr0y7ByAiIu2lQiAiknIqBCIiKadCICKScioEIiIpd1q7BzAXZ555pp933nntHoaISEd54oknXnb3wfLlHVkIzjvvPMbGxto9DBGRjmJmPwlbrl1DIiIpp0IgIpJyKgQiIimnQiAiknIqBCIiKRfLrCEzuxt4F3DY3d9aWDYA3AucB+wDrnL3V0LuewnwWSALfNHdPxXHmGR+Gt05zsj2vRw6Osk5/Tk2r1/G8AVDc3qcm7c9zdHJKQB6gwynB1mOHpvinP4c570+x7++cITScypmDJYM9vHc4dcoPdViLshw6xW/zn1j+/ne80fm9LoM+M0lAxXPGeas1/Ww46Z3VLyeWtslrm0nUs7iOPuomf0W8HPg70sKwaeBI+7+KTP7C2CBu3+k7H5Z4MfAO4CDwOPARnf/YbXnW7VqlWv6aOcZ3TnOjQ/sYXJqemZZLshy6xXLG/qDNrpznM337WbqZOeeObe0GNSzXeLadpJuZvaEu68qXx7LriF3/y5Q/l+py4AvFS5/CRgOuetq4Dl3f8HdjwNfLdxPutDI9r2z/pABTE5NM7J9b8OP08lFAOClnx2fuVzPdolr24mESfIYwVnu/iJA4ffCkHWGgAMl1w8WllUws01mNmZmYxMTE7EPVpJ36OhkQ8sbfZxOVc92iWvbiYRp98FiC1kW+l89d7/L3Ve5+6rBwYqEtHSAc/pzDS1v9HE6VT3bJa5tJxImyULwkpmdDVD4fThknYPAopLr5wKHEhyTtNHm9cvIBdlZy3JBls3rlzX8OEEm7P8QneOs1/XMXK5nu8S17UTCJFkItgHXFy5fD3wjZJ3HgaVm9iYz6wGuKdxPutDwBUPcesVyhvpzGDDUn5vTwc7hC4YY2bCC/lwws6w3yLCgN5h53HVLBrCyWpExWLqwr+JraC7I8JmrV7JuycCcXhfkv9qGPWeY8llD9WyXuLadSJi4Zg1tBS4CzgReAj4OjAJfAxYD+4EN7n7EzM4hP0300sJ9LwU+Q3766N3ufkut59OsIRGRxkXNGoolR+DuGyNu+p2QdQ8Bl5Zcfwh4KI5xiIhI49p9sFhERNqsI/sRSOcrTcmekQswYyYVXC0x+7HRPWzdcYBpd7JmbFyziC3DyyOf43/cuyt8GlqJIAM9p2V57Xh+nn4uyGDAsamTs9bLGkzXeLB1Swa454YLufYL3w9NKQ8pESzzUCzHCFpNxwg6W1hKtlRUYvZjo3v48qP7K9a/bu3iimIwunOcD967K7YxN+JXTs/y01+GvzZQIljaJ9FksUgjwlKypaISs1t3HAhZO3x5OxO31YoAKBEs848KgbRcPWnYsHWmI769hi2f74nb+T4+SRcVAmm5etKwYetkIybphy2f74nb+T4+SRcVAmm5sJRsqajE7MY1i0LWDl/ezsTtr5we/dpAiWCZf1QIpOXKU7L9uWBWKjjqQOqW4eVct3bxzDeArFnogeLic3zm6pWhJ7MqF2Sgr+fUH+9ckKE3qPynka3jwdYtGeCpT1wSmVJWIljmI80aEhFJCc0aEhGRUCoEIiIpp2SxNK3RXrrF9cdLplCWp4RLE8TlggyMbFgJMOt5L37zII88M8Gho5P0nJbhlydOVtx3vji9ZHw9WeN4SWTZyDflGCp7TaXbVv2LJU46RiBNabSXbq1U8XVrFwOEJojLBVljqtY5H7pMLsjynrcNcf8T4+pfLA3TMQJJRKO9dGulirfuOBCZIC6XtiIA+W27dccB9S+WWGnXkDSl0V66tRK1UelhOSVqGymtLHOlbwTSlEZ76dZK1GbNIhPEkhe1fZRWlrlKtBCY2TIz21Xy81Mz+2DZOheZ2asl6/xlkmOSeDXaS7dWqnjjmkWRCeJyQT0Jry6TC7JsXLNI/YslVonuGnL3vcBKADPLAuPAgyGr/rO7vyvJsUgyigcn653BUrp+tVlDgGYNVZk1tOqNA5o1JLFp2awhM3sn8HF3X1e2/CLgzxspBJo1JCLSuPkwa+gaYGvEbRea2W4z+6aZnR+2gpltMrMxMxubmJhIbpQiIinTkkJgZj3Au4H7Qm5+Eniju68APgeMhj2Gu9/l7qvcfdXg4GBiYxURSZtWTR/9XeBJd3+p/AZ3/2nJ5YfM7PNmdqa7v9yisUmLlKZh+3sD3OHVyco+xaM7x7l529McnZyq63H7erLccvly/vaRZ3n28GtJvoTYGfCbSwbY9++T2t8vbdOqQrCRiN1CZvYG4CV3dzNbTf5byr+3aFzSIuWJ4leOnfojP350khsf2DNzffN9u5k6Wf+xq9eOT7etP3GzHGY1uS/dFioG0iqJFwIz6wXeAby3ZNn7ANz9TuBK4M/M7AQwCVzjnXjeC6mqkT7FjRSBblTcFioE0iqJFwJ3Pwa8vmzZnSWX7wDuSHoc0l5z7VOcVtoW0kpKFktL1NunWOnYPG0HaSUVAmmJevsUb16/jCCTvsRwKaWEpdVUCKQlyvsUL+gN6M9V9ikevmCIkQ0r6M8FdT92X0+Wz1y9kqUL+xIbf1KMfJ/j4nZRT2NpB/UjEBFJifmQLBYRkXlIhUBEJOXUmEZiM9fexcWk8c9/McVUjROGDhUeF2gofTxfGXDt2sVsGV7O6M5xPnL/Uw2fNXVIaWRpko4RSCzi7l1cTZA1pqed+XuS6catWzLA9184wlyzdOpZLPXQMQJJVNy9i6uZ6rIiAPnTTDQTqFbPYmmGCoHEIu7exdI4bVOZKxUCiUXcvYulcdqmMlcqBBKLuHsXVxNkres+uOuWDNBMoFppZGlGt/17kjYpTw7XSsiGJY2DOj6NQ/05Rq5cwe1Xr2wofTxfGXDd2sXcc8OF3H7VSk4/rfF/kkojS7M0a0hEJCU0a0hEREKpEIiIpFwrOpTtA34GTAMnyr+WmJkBnwUuBY4Bf+TuTyY9rrRrNAXc7uf62Ogetu44wLQ7Rr7FY7fpzwXc/O7zGb5gqBC4e4rJQtQ6Y/D7a04lkFv13kk6tOoUExdXaUb/u8DSws8a4O8KvyUh5aneJPvkxvFcHxvdw5cf3T9zvRuLAMDRySk237ebsZ8c4SuP7p8Vmjvp8OVH9/NvEz/nyf2vtuS9k/SYD7uGLgP+3vMeBfrN7Ox2D6qbNZoCbvdzbd1xIO5hzVtTJ52tOw5EJqe/9/yRlr13kh6tKAQOfNvMnjCzTSG3DwGl/9IPFpbNYmabzGzMzMYmJiYSGmo6tDLtG8dzTXfgzLZmzOX1KlUszWhFIVjn7r9BfhfQ+83st8puD4vRVPxLcPe73H2Vu68aHBxMYpyp0cq0bxzPlbV0ta6cy+tVqliakXghcPdDhd+HgQeB1WWrHAQWlVw/FziU9LjSrNEUcLufa+OaRbVX6hJBxti4ZlHkP8x1SwZa9t5JeiRaCMysz8xeV7wMvBP4Qdlq24A/tLy1wKvu/mKS40q7RlPA7X6uLcPLuW7t4pn/KXfr94P+XMDIhhVsGV7O7VevJFcStc7YqQRyq947SY9Ek8Vm9h/JfwuA/Aylr7j7LWb2PgB3v7MwffQO4BLy00f/2N2rxoaVLBYRaVxUsjjR6aPu/gKwImT5nSWXHXh/kuMQEZFo82H6qIiItJF6FkssRneOc9ODe3jt+Kk57n09WW65PLpV5Sf+4WleOZbvOVxMC5emhvt6shw/MV3RxzjIULO3cacx4FcX9vHCxLFZ00eH+nNc/OZBHnlmoiJJXJowPiMXYAZHj00pbdxlWpEk19lHpWmjO8f58H27mQ7ptZjNGLdtWDHrgzu6c5zNX9/N1HTnffbmg1yQ5T1vG+L+J8Yj232qh3F3aLQXeC06+6gkZmT73tAiADB90itSryPb96oINGFyapqtOw5U7fmstHF3aNVZAFQIpGm1Uq3ltysF27x60sfazp2vVWcBUCGQptVKtZbfrhRs8+pJH2s7d75WnQVAhUCatnn9MrIRDXezGatIvW5ev4wg262xsOTlgiwb1yyq2vNZaePu0KqzAKgQSNOGLxjitg0r6OuZ/YHt68lWHCgurj9y5QoW9J7qOWxlv4v3D+tjXE9v405jwNKFfRX/0x/qz3Hd2sUVSeItw8tnJYz7cwELegOljbtMq84CoFlDIiIpoVlDIiISKjWBMrX3a41rv/B9vvf8kZnrp5+WYfFAjmcPvzZrvaGyYNRHH3iKYyEpseJ6ADdve5qjk1PJvoA2Gwr5bBY/u+MRM0Wylj9j6Zbh5a0apnSZVOwaijuUIeHKi0AtxWDUV3bsJyKGAECQNaanPbJrV7cp/WyGfXajXLd2sYqBVJXqXUOtbM2YZo0UATgVjKpWBACmUlQEYPZnM+yzGyVNLT0lXqkoBK1szSiNSVsbynoVP5tq6SmtkIpC0MrWjNKYtLWhrFfxs6mWntIKSXcoW2Rmj5jZj8zsaTP77yHrXGRmr5rZrsLPX8Y9jla2ZkyzdUsGGlq/GIyKyKLNCLKWjv+xFJR+NsM+u1HS1NJT4pX0v68TwIfd/deAteSb178lZL1/dveVhZ9Pxj2IVrZmTLN7briwohicflqGpQv7KtYtDUbdftVKeiNSYkP9OUauXMHtV6+kPxeErtNNyj+bpZ/dKFkzHSiWprR01pCZfQO4w90fLll2EfDn7v6ueh9HgTIRkca1fdaQmZ0HXADsCLn5QjPbbWbfNLPzI+6/yczGzGxsYmIiyaGKiKRKSwqBmf0H4H7gg+7+07KbnwTe6O4rgM8Bo2GP4e53ufsqd181ODiY6HhFRNIk8WSxmQXki8A97v5A+e2lhcHdHzKzz5vZme7+ctJjk/YY3Tk+KyW8oDfgLWe/jkdfeCXVUyCLbTrL08Vh2+vjv3e+jnFJbBItBGZmwP8GfuTut0es8wbgJXd3M1tN/lvKvyc5Lmmf0Z3jbL5vN1MlKbJXjk01HEbrRsUtMn50khsf2DOzPGx7bf76bgAVA4lF0t8I1gF/AOwxs12FZR8FFgO4+53AlcCfmdkJYBK4xjvxvBdSl5Hte2f9UZNwpenisO01NZ1vAapCIHFItBC4+78w+xTzYevcAdyR5Dhk/lCau36NtgAVmas05XRkHlCau37n9Oeqbi9tS4mLCoG01Ob1ywhqRYllJl0ctb2CbGULUJG5Sk0/Apkfivu0NWuoUtSsIajcXpo1JHFKRT8CERGZB8liERGZn1QIRERSTscIJFQzPZ5L73tGLsAsH4KS2hb0BrjDq5NTnNOfo7cnM6vf87olA9xzw4XqwS2x0jECqdBMj+dGeuzK3Cxd2MfBV36hHtzSMB0jkLo10+O5kR67MjfPHn5NPbglVioEUqGZHs9Ku7aPtr3MlQqBVGimx7PSru2jbS9zpUIgFZrp8dxIj12Zm6UL+9SDW2KlQiAVmunxXH7f/lzAgt7u7zUclwW9Af25YGa7l/d7XrdkgIc/dJF6cEusNGtIRCQlNGtIRERCqRCIiKRcK3oWXwJ8FsgCX3T3T5XdboXbLwWOAX/k7k8mPa60KCZQx49OkjVj2j307JZh9ylPrZY+liQrY5A1mDpZfb2h/hwXv3mQR56ZmHm/yq8rdSy1JHqMwMyywI+BdwAHgceBje7+w5J1LgX+K/lCsAb4rLuvqfa4OkZQn2op36gkalSq+D1vG+L+J8YVFutASh1LUbuOEawGnnP3F9z9OPBV4LKydS4D/t7zHgX6zezshMeVCtVSvlFJ1KhU8dYdB1QEOpRSx1JL0oVgCDhQcv1gYVmj62Bmm8xszMzGJiYmYh9oN5pLz9uo+6S5YUw3UOpYqkm6EIT1JCz/i1LPOrj7Xe6+yt1XDQ4OxjK4blcraRp2e9R9sqb2kp1MqWOpJulCcBBYVHL9XODQHNaROaiW8o1KokalijeuWaTEcIdS6lhqSboQPA4sNbM3mVkPcA2wrWydbcAfWt5a4FV3fzHhcaVCacoXTv2vvloSNSpVvGV4+azHkmRlDII6/nUO9ee4bu3iWe9X+XUdKJZaEk8WF2YFfYb89NG73f0WM3sfgLvfWZg+egdwCfnpo3/s7lWnBGnWkIhI46JmDSWeI3D3h4CHypbdWXLZgfcnPQ4REQmnZLGISMqpZ7E0bXTnODc9uIfXjp/KGRj5qV/F30W5IMN73nYujzwzoYRyDcX+xUcnZ/d7zgUZbr3i12ft91cPY2mGCoE0ZXTnOB++bzfTJ2cfa/Ky30WTUyf58qP7WzK2TvfKsanQ5ZNTJ/nQvbsAZk79UZoGHz86yY0P7Jm5XaQW7RqSpoxs31tRBCR5J2EmLdxMj2kRUCGQJimx2j7Fbd9Mj2kRUCGQJimx2j7Fbd9Mj2kRUCGQJm1ev4xsRqefaLUMzKSFm+kxLQIqBNKk4QuGuG3DCvp6Zv8hsrLfRbkgM5N8leqK/YvL5YIMt1+9cuZAcDM9pkVAPYtFRFJDPYtFRCSUCoGISMopUJYi1foXA00lU0d3jrP5vl2RPXZLE8YLegM+/nvnM/aTIwqXlYjqKa3UsCRNxwhSolr/4iBjYDA1feqz0Eif29Gd43ywkHStV8ZAObRoxe0PhPaQ1sFgmQsdI0i5av2Lp076rCIAjSVT55JgVRGorrj9lRqWVtCuoZSYS8q03vsowZqMattV21zipG8EKTGXlGm991GCNRnn9OeUGpaWSKwQmNmImT1jZk+Z2YNm1h+x3j4z22Nmu8xMO/4TUq1/cZAxguzs6FcjydS5JFgVRq6uuP2VGpZWSHLX0MPAje5+wsz+GrgR+EjEuhe7+8sJjiX1igcWk5g1VFxPs4aaEzVrCJqb0SVSS0tmDZnZ5cCV7n5tyG37gFWNFALNGhIRaVy7Zw39CfDNiNsc+LaZPWFmm6IewMw2mdmYmY1NTEwkMkgRkTRqateQmX0HeEPITTe5+zcK69wEnADuiXiYde5+yMwWAg+b2TPu/t3yldz9LuAuyH8jaGbcIiJySlOFwN3fXu12M7seeBfwOx6xD8rdDxV+HzazB4HVQEUhkNlGd45z87anZ/rZFve7x7nveHTnOJ/4h6dnWib25wJufvf5QPixhvNen+Nfnz8yqz1lb5DhWNSBAwEga1Aa4+jryXLL5QqMSeskdrDYzC4hf3D4t939WMQ6fUDG3X9WuPxO4JNJjalb5E/nsJupklTWK8em2Pz13UA8fWpHd46z+eu7ZwXNjk5O8aGv7SJrNvPc04X6Pn50MrQZvYpAbWVZPl47Ps2H74vvvRSpJcljBHcAryO/u2eXmd0JYGbnmNlDhXXOAv7FzHYDjwH/6O7fSnBMXWFk+95ZRaBoatpjS5yObN9bkTaGfCI47LklXtMn43svRWpJ7BuBu/9qxPJDwKWFyy8AK5IaQ7dqReJUydX203sgraJkcQeqliqNK3Gq5Gr76T2QVlEh6ECb1y/LnzG0TJC12BKnm9cvq0gbQz4RHPbcEq9sJr73UqQWFYIONHzBECMbVszqZ7ugN2DkyhWxHVwcvmCIkStXsKD31HP05wJuv2olIxtWzPQczlq+KAz151i3ZKCiR3FvoI9YLeX1tq8ny20b4nsvRWpRPwIRkZRod7JYRETmKRUCEZGUU2OaLlRvj9ta65UniwGCDJxwcM+fUbS3J8ux49OckQt4dXKKztvR2DphZxdtRUJcpBYVgi5T3pt4/OgkNz6wB6Dij3y19cKSxcCs00w7+RQsMPOHTKKVprBvfGAPYz85wr2PHUg0IS5SD+0a6jL19rittV5UsljiMTk1zdYdBxJPiIvUQ4Wgy0SlUcuX11pPqdbkTVeZsaftL62kQtBl6u1xW2s9pVqTV8xghNH2l1ZSIegy9fa4rbVeVLJY4pELsmxcsyjxhLhIPXSwuMuU9iauNmuo1nrF35o1FJ+wWUOr3jigWUPSdkoWi4ikhJLFIiISKskOZTcDNwDFTvMfdfeHQta7BPgskAW+6O6fSmpM3aQ0DHZGLsAMjh6bmnW5dHfPx0b3sHXHAabdyRicflqGyamTFbsr7hvbz/eePzLzPOuWDHDPDRfOet7y3UVFC3oDfjE1zaS6ks1SbPEZtbsnrgCgyFwltmuoUAh+7u7/s8o6WeDHwDuAg8DjwEZ3/2G1x077rqHyMFg1uSDLbyw+Y9Yf9ygZy3cgK1csBlEhM6ktyBgjIWcUDXsvc0GWW69YXjUAGLWeSDXzddfQauA5d3/B3Y8DXwUua/OY5r2wMFiUyanpuooAhBcBYOb+CpnN3VRE68m4AoAizUi6EHzAzJ4ys7vNbEHI7UPAgZLrBwvLKpjZJjMbM7OxiYmJsFVSo11hI4WcmhO2/eIKAIo0o6lCYGbfMbMfhPxcBvwdsARYCbwI3Bb2ECHLQv/L6e53ufsqd181ODjYzLA7XrvCRgo5NSds+8UVABRpRlOFwN3f7u5vDfn5hru/5O7T7n4S+AL53UDlDgKLSq6fCxxqZkxpEBYGi5ILsqxbMlDXulEdKIv3V8hs7oKI1pNxBQBFmpHYriEzO7vk6uXAD0JWexxYamZvMrMe4BpgW1Jj6hbDFwxx6xXLGerPYeRnpSzoDSouD/XnuPWK5dxzw4Vct3bxzCkNMga5QgvJ0laTt1+1sqJolM4aCmtfWWpBbzDzuHJKfy4IPVAMle9l8T0LCwDWs57IXCQ5a+j/kt8t5MA+4L3u/qKZnUN+muilhfUuBT5Dfvro3e5+S63HTvusIRGRuYiaNZRYjsDd/yBi+SHg0pLrDwEV+QIREWkNfY8XEUk5nXSuA5WmhLNmbFyziC3Dy2duD0sdv3JsCuPUlKziyc0Abnpwz0ynMQOuXbuYLcPLK1LEuSCDAceUHE5EeYpbpFV00rkO87HRPXz50f0Vy68r+eNdb+o4mzFOnvTQ+brrlgzw2L5XFCBrMRUDSdJ8TRZLg7buOFB1eSOp4+mIIgD5NLGKQOvVmwIXiZMKQYeJam9YXK6kqYg0SoWgw0S1NywuV9JURBqlQtBhNq5ZVHV5I6njbMZCz/EB+X3VShG3Xr0pcJE4qRB0mC3Dy2elhLNmMweKITp1DLNP7LSgN+C2DSv4m6tX0tdzqnAY+QPP99xwYUWKOBdk6FVyODE6UCztollDIiIpoVlDIiISSoVARCTllCyeZ8L60gIN9arNh8qeqtk7OGPw+2sWs+qNA7Me/+I3D/LIMxMz13t7Mjx7+LVZ980alMYMsoU2l5my5XKKGVy75tTxHPUglkYk+XnRMYJ5JCwVHGQNPN/qsKhar9rRneN86N5dNHISiKhexZKM69bmi696EEu94upZrWMEHSAsFTw17bOKAFTvVTuyfW9DRQBUBFpt644D6kEsDUn686JCMI80kgpWD9vONe2u908akvTnRYVgHmkkFawetp0ra6b3TxqS9OclyVaV95rZrsLPPjPbFbHePjPbU1iv+3b8NyAsFRxkjaCsmXC1XrWb1y9r+E2N6lUsydi4ZpF6EEtDkv68JNmh7OriZTO7DXi1yuoXu/vLSY2lUxQP+jQza6i4XLOG5p/yWUPQ2GwwSa+ovw0dM2vIzAzYD/wXd3825PZ9wKpGCkG3zhoSEUlSO2cN/WfgpbAiUODAt83sCTPbFPUgZrbJzMbMbGxiYiKRgYqIpFFTu4bM7DvAG0Juusndv1G4vBHYWuVh1rn7ITNbCDxsZs+4+3fLV3L3u4C7IP+NoJlxi4jIKU0VAnd/e7Xbzew04ArgbVUe41Dh92EzexBYDVQUgm4RdzqwvK9wfy7g5nefP/OYozvH+cj9T/HLE433GV66sI+HP3RR1dcx3oXTHUt7Oyf5HNeunX28IEwcSXORWhI9RmBmlwA3uvtvR9zeB2Tc/WeFyw8Dn3T3b1V73E49RhBXOrD08TZ/fXdFS8kgY4xsWAHAh762q6nAWFgxaKQvslR3XZViEJo0zxgYs95zJZKlXu06RnANZbuFzOwcM3uocPUs4F/MbDfwGPCPtYpAJ4s7HTiyfW9oX+Gpk87I9r35lHGTdb58tlDxeVUE4hHVgxoikuYnveI9VyJZmpXoSefc/Y9Clh0CLi1cfgFYkeQY5pO404HV7pdkQlXp1/hE9aCGeJLmIvVQsriF4k4HVrvfOf25xFKqSr/GJ6oHNcSTNBephwpBC8WdDty8flloX+EgY2xevyyfMm4yNbx0YV/o89bbF1mqi+pBDRFJ84xVvOdKJEuz1I+gheJOBxbvV23WEBD7rKHS16FZQ3N/jlqzhuJImovUQ/0IRERSQv0IREQklAqBiEjK6RhBBytN92bNmHZnqGSf8ejOcW7e9jRHJ/PHD/p6srg7x2qclbRcfy7ADI4em6q7Z3JxH/YZhfu+cmxqZoydLAN1d4ArPduo+hPLfKZjBB2qWro3F2R5z9uGuPexAxVtLuNQq2eyUsezrVsywJP7X1V/Ymk7HSPoMtXSvZNT02zdkUwRKD5+tZ7JKgKzfe/5I+pPLPOaCkGHqpUkTXoXjHruNk/bSuYLFYIOVStJWi2xmuTzK+FaP20rmS9UCDpUtXRvLsiycc2iil7HcanVM1mp49nWLRlQf2KZ11QIOtTwBUPcesVyhgr/qyx+Axjqz3HrFcvZMryckQ0r6M8FM/fp68nSGzT+lvfnAhb0BljJ41frmVwcl5Xct3SMnayRrWeWP830PTdcOGub1NqGIq2mWUMiIimhWUMiIhJKhUBEJOWabV6/AbgZ+DVgtbuPldx2I/CnwDTw39x9e8j9B4B7gfOAfcBV7v5KM2PqRrVSqdd+4ft87/kjM9eXLuzj5Z8fnzkjaU/WOB7SyazUgt6Aj//e+UD4WUX7erLccvnymcRyeaI5LDUcZOC0bIbJBpPMna64rUBnCZXO0NQxAjP7NfKJ+/8F/HmxEJjZW8i3qFwNnAN8B/hP7j5ddv9PA0fc/VNm9hfAAnf/SK3nTdMxglp9jsuLQDOyGSMDkUG0bMbYuHoR9z8xrtBYDRnLHxwv3ZZKE0u7JXKMwN1/5O5h8cjLgK+6+y/d/d+A58gXhbD1vlS4/CVguJnxdKNafY7jKgIA0ye9ahp5+qSzdccBFYE6nPTKgqo0scxXSR0jGAJKu3IfLCwrd5a7vwhQ+L0w6gHNbJOZjZnZ2MTERKyDnc/mW4K3008a125KE8t8VLMQmNl3zOwHIT+XVbtbyLKm/oK4+13uvsrdVw0ODjbzUB1lviV4uyEL0E5KE8t8VLMQuPvb3f2tIT/fqHK3g0BpM9ZzgUMh671kZmcDFH4fbmTwaVCrz/G6JQOxPVc2Y1XTyNmMsXHNIiWH65AxKral0sQyXyW1a2gbcI2ZnW5mbwKWAo9FrHd94fL1QLXikkrlSd3yVOo9N1xYUQyWLuybSfNCftZQLQt6A27bsIKRDStm0sql+nqy3LZhBVuGl4cmmsO+KQQZyM0hydzp+nqy3H7VypltqTSxzHfNzhq6HPgcMAgcBXa5+/rCbTcBfwKcAD7o7t8sLP8icKe7j5nZ64GvAYuB/cAGd6959DNNs4ZEROISNWtIp5gQEUkJnWJCRERCqRCIiKScCoGISMqpEIiIpFxHHiw2swngJ+0eRx3OBF5u9yBaSK+3+6XtNXfb632ju1ckcjuyEHQKMxsLO0LfrfR6u1/aXnNaXq92DYmIpJwKgYhIyqkQJOuudg+gxfR6u1/aXnMqXq+OEYiIpJy+EYiIpJwKgYhIyqkQxMzMNpjZ02Z20sxWld12o5k9Z2Z7zWx9u8aYJDO72czGzWxX4efSdo8pCWZ2SeF9fK7Qb7urmdk+M9tTeE+78oyPZna3mR02sx+ULBsws4fN7NnC7wXtHGNSVAji9wPgCuC7pQvN7C3ANcD5wCXA582sWzu8/I27ryz8PNTuwcSt8L79LfC7wFuAjYX3t9tdXHhPu3Ve/f8h/2+z1F8A/+TuS4F/KlzvOioEMXP3H7l7WIfyy4Cvuvsv3f3fgOeA1a0dncRkNfCcu7/g7seBr5J/f6WDuft3gfJ+KJcBXypc/hIw3MoxtYoKQesMAQdKrh8sLOtGHzCzpwpftbvxq3Sa3ssiB75tZk+Y2aZ2D6aFznL3FwEKvxe2eTyJOK3dA+hEZvYd4A0hN91UpZdzWL/Ijpy7W+31A38H/BX51/ZXwG3kO9V1k655Lxuwzt0PmdlC4GEze6bwP2jpAioEc+Dub5/D3Q4Ci0qunwscimdErVXv6zezLwD/L+HhtEPXvJf1cvdDhd+HzexB8rvH0lAIXjKzs939RTM7Gzjc7gElQbuGWmcbcI2ZnW5mbwKWAo+1eUyxK/xjKbqc/MHzbvM4sNTM3mRmPeQnAWxr85gSY2Z9Zva64mXgnXTn+xpmG3B94fL1QNQ3/o6mbwQxM7PLgc8Bg8A/mtkud1/v7k+b2deAHwIngPe7+3Q7x5qQT5vZSvK7SvYB723raBLg7ifM7APAdiAL3O3uT7d5WEk6C3jQzCD/N+Mr7v6t9g4pfma2FbgIONPMDgIfBz4FfM3M/hTYD2xo3wiTo1NMiIiknHYNiYiknAqBiEjKqRCIiKScCoGISMqpEIiIpJwKgYhIyqkQiIik3P8H9deDk6GrDVgAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_pred_train, data.y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine Data and Modeling Capabilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Model... nn\n",
      "Train Score: 0.08914622641393599\n",
      "Test Score: 0.15358331787573642\n",
      ".................. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class model_suite():\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "\n",
    "    def builder(self, regr, x_train, x_test, y_train, y_test):\n",
    "        if regr == 'nn':\n",
    "            vanilla = NN()\n",
    "            regressor, y_predict_train, y_predict_test = vanilla.Vanilla_NN_Reg(x_train = x_train, x_test = x_test, y_train = y_train)\n",
    "            train_score = vanilla.Score(regressor, x_train, y_train)\n",
    "            test_score = vanilla.Score(regressor, x_test, y_test)\n",
    "            print(f'Basic Model... {regr}')\n",
    "            print(f'Train Score: {train_score}')\n",
    "            print(f'Test Score: {test_score}')\n",
    "            print('.................. \\n')\n",
    "            # -------------------------------\n",
    "            return regressor\n",
    "\n",
    "    def model_run(self, regr, x_train, x_test, y_train, y_test):\n",
    "        self.models['test_model'] = self.builder(regr, x_train, x_test, y_train, y_test)\n",
    "\n",
    "models = model_suite()\n",
    "models.model_run(regr='nn',x_train=data.x_train, x_test=data.x_test, y_train=data.y_train, y_test=data.y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "       expected_lead_time  material_order_history  avg_material_late  \\\n0                    84.0                   321.0          -6.476636   \n1                    78.0                  2332.0          -6.687590   \n2                     1.0                  6109.0           0.255852   \n3                     7.0                 31199.0          -0.501606   \n4                    84.0                   321.0          -6.476636   \n...                   ...                     ...                ...   \n59698                 7.0                 31199.0          -0.501606   \n59699                 7.0                 31199.0          -0.501606   \n59701                 2.0                 11390.0          -2.278994   \n59702                 7.0                 31199.0          -0.501606   \n59703                 2.0                 11390.0          -2.278994   \n\n       supplier_material_order_history  avg_supplier_material_late  \\\n0                                 27.0                    4.037037   \n1                                  7.0                   -3.285714   \n2                               5449.0                    0.272392   \n3                              30055.0                   -0.395743   \n4                                 27.0                    4.037037   \n...                                ...                         ...   \n59698                          30055.0                   -0.395743   \n59699                          30055.0                   -0.395743   \n59701                          11388.0                   -2.279195   \n59702                          30055.0                   -0.395743   \n59703                          11388.0                   -2.279195   \n\n       supplier_total_order_history  avg_supplier_general_late  \\\n0                              28.0                   4.035714   \n1                             349.0                  -2.155224   \n2                            5449.0                   0.272392   \n3                           30067.0                  -0.394674   \n4                              28.0                   4.035714   \n...                             ...                        ...   \n59698                       30067.0                  -0.394674   \n59699                       30067.0                  -0.394674   \n59701                       11866.0                  -2.288488   \n59702                       30067.0                  -0.394674   \n59703                       11866.0                  -2.288488   \n\n       number_line_items       avg_MOQ  avg_unit_price  ...  dayofweek-Monday  \\\n0                     25      0.440273      517.727440  ...                 0   \n1                      1      0.000268       52.358737  ...                 0   \n2                      1  31012.938776       17.964587  ...                 0   \n3                     17    868.658120        3.905899  ...                 0   \n4                     25      0.440273      517.727440  ...                 0   \n...                  ...           ...             ...  ...               ...   \n59698                 30    868.658120        3.905899  ...                 0   \n59699                 30    868.658120        3.905899  ...                 0   \n59701                 11   2678.519713        1.988488  ...                 0   \n59702                 30    868.658120        3.905899  ...                 0   \n59703                 11   2678.519713        1.988488  ...                 0   \n\n       dayofweek-Saturday  dayofweek-Sunday  dayofweek-Thursday  \\\n0                       0                 0                   0   \n1                       0                 0                   0   \n2                       0                 0                   0   \n3                       0                 0                   0   \n4                       0                 0                   0   \n...                   ...               ...                 ...   \n59698                   0                 0                   0   \n59699                   0                 0                   0   \n59701                   0                 0                   0   \n59702                   0                 0                   0   \n59703                   0                 0                   0   \n\n       dayofweek-Tuesday  dayofweek-Wednesday  delivery_season-Fall  \\\n0                      0                    0                     0   \n1                      0                    0                     0   \n2                      0                    0                     0   \n3                      0                    0                     0   \n4                      0                    0                     0   \n...                  ...                  ...                   ...   \n59698                  0                    0                     0   \n59699                  0                    0                     0   \n59701                  0                    0                     0   \n59702                  0                    0                     0   \n59703                  0                    0                     0   \n\n       delivery_season-Spring  delivery_season-Summer  delivery_season-Winter  \n0                           1                       0                       0  \n1                           1                       0                       0  \n2                           1                       0                       0  \n3                           1                       0                       0  \n4                           1                       0                       0  \n...                       ...                     ...                     ...  \n59698                       1                       0                       0  \n59699                       1                       0                       0  \n59701                       1                       0                       0  \n59702                       1                       0                       0  \n59703                       1                       0                       0  \n\n[57407 rows x 82 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>expected_lead_time</th>\n      <th>material_order_history</th>\n      <th>avg_material_late</th>\n      <th>supplier_material_order_history</th>\n      <th>avg_supplier_material_late</th>\n      <th>supplier_total_order_history</th>\n      <th>avg_supplier_general_late</th>\n      <th>number_line_items</th>\n      <th>avg_MOQ</th>\n      <th>avg_unit_price</th>\n      <th>...</th>\n      <th>dayofweek-Monday</th>\n      <th>dayofweek-Saturday</th>\n      <th>dayofweek-Sunday</th>\n      <th>dayofweek-Thursday</th>\n      <th>dayofweek-Tuesday</th>\n      <th>dayofweek-Wednesday</th>\n      <th>delivery_season-Fall</th>\n      <th>delivery_season-Spring</th>\n      <th>delivery_season-Summer</th>\n      <th>delivery_season-Winter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84.0</td>\n      <td>321.0</td>\n      <td>-6.476636</td>\n      <td>27.0</td>\n      <td>4.037037</td>\n      <td>28.0</td>\n      <td>4.035714</td>\n      <td>25</td>\n      <td>0.440273</td>\n      <td>517.727440</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>78.0</td>\n      <td>2332.0</td>\n      <td>-6.687590</td>\n      <td>7.0</td>\n      <td>-3.285714</td>\n      <td>349.0</td>\n      <td>-2.155224</td>\n      <td>1</td>\n      <td>0.000268</td>\n      <td>52.358737</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>6109.0</td>\n      <td>0.255852</td>\n      <td>5449.0</td>\n      <td>0.272392</td>\n      <td>5449.0</td>\n      <td>0.272392</td>\n      <td>1</td>\n      <td>31012.938776</td>\n      <td>17.964587</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.0</td>\n      <td>31199.0</td>\n      <td>-0.501606</td>\n      <td>30055.0</td>\n      <td>-0.395743</td>\n      <td>30067.0</td>\n      <td>-0.394674</td>\n      <td>17</td>\n      <td>868.658120</td>\n      <td>3.905899</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84.0</td>\n      <td>321.0</td>\n      <td>-6.476636</td>\n      <td>27.0</td>\n      <td>4.037037</td>\n      <td>28.0</td>\n      <td>4.035714</td>\n      <td>25</td>\n      <td>0.440273</td>\n      <td>517.727440</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59698</th>\n      <td>7.0</td>\n      <td>31199.0</td>\n      <td>-0.501606</td>\n      <td>30055.0</td>\n      <td>-0.395743</td>\n      <td>30067.0</td>\n      <td>-0.394674</td>\n      <td>30</td>\n      <td>868.658120</td>\n      <td>3.905899</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59699</th>\n      <td>7.0</td>\n      <td>31199.0</td>\n      <td>-0.501606</td>\n      <td>30055.0</td>\n      <td>-0.395743</td>\n      <td>30067.0</td>\n      <td>-0.394674</td>\n      <td>30</td>\n      <td>868.658120</td>\n      <td>3.905899</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59701</th>\n      <td>2.0</td>\n      <td>11390.0</td>\n      <td>-2.278994</td>\n      <td>11388.0</td>\n      <td>-2.279195</td>\n      <td>11866.0</td>\n      <td>-2.288488</td>\n      <td>11</td>\n      <td>2678.519713</td>\n      <td>1.988488</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59702</th>\n      <td>7.0</td>\n      <td>31199.0</td>\n      <td>-0.501606</td>\n      <td>30055.0</td>\n      <td>-0.395743</td>\n      <td>30067.0</td>\n      <td>-0.394674</td>\n      <td>30</td>\n      <td>868.658120</td>\n      <td>3.905899</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59703</th>\n      <td>2.0</td>\n      <td>11390.0</td>\n      <td>-2.278994</td>\n      <td>11388.0</td>\n      <td>-2.279195</td>\n      <td>11866.0</td>\n      <td>-2.288488</td>\n      <td>11</td>\n      <td>2678.519713</td>\n      <td>1.988488</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57407 rows × 82 columns</p>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# corr = df[\n",
    "# features\n",
    "# ].corr()\n",
    "# fig = px.imshow(corr)\n",
    "# fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}